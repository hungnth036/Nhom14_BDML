{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd06f818",
   "metadata": {},
   "source": [
    "# 📘 BDML Project Report Template\n",
    "\n",
    "Notebook này cung cấp dàn ý và gợi ý nội dung cho báo cáo môn Big Data & Machine Learning (BDML) theo hướng dẫn của Thầy Quách Đình Hoàng (19/09/2025).\n",
    "\n",
    "- Ngôn ngữ chính: Tiếng Việt (có thể bổ sung song ngữ nếu cần).\n",
    "- Độ dài tổng: 8-12 trang A4 (tham khảo).\n",
    "- Các phần đánh số 1-9 tương ứng với cấu trúc bắt buộc.\n",
    "- Thay thế nội dung gợi ý bằng dữ liệu và kết quả cụ thể của nhóm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd4fcf",
   "metadata": {},
   "source": [
    "## 1. Tóm tắt (Abstract)\n",
    "\n",
    "Tiểu đường là một trong những bệnh mãn tính phổ biến nhất trên thế giới, gây ra những biến chứng nghiêm trọng nếu không được chẩn đoán và điều trị kịp thời. Dự án này nhằm xây dựng một hệ thống tự động để dự đoán khả năng mắc bệnh tiểu đường dựa trên các chỉ số sức khỏe của bệnh nhân. Chúng tôi sử dụng tập dữ liệu Pima Indians Diabetes từ Kaggle, bao gồm 768 mẫu và 8 đặc trưng y học (glucose, BMI, tuổi, v.v.). Để xử lý dữ liệu, nhóm áp dụng các kỹ thuật tiền xử lý (xử lý giá trị thiếu, chuẩn hóa), rồi huấn luyện và so sánh bốn mô hình máy học: Logistic Regression, Random Forest, XGBoost, và KNN. Kết quả cho thấy mô hình Random Forest đạt độ chính xác cao nhất (76.6%), ROC-AUC 0.8307, và F1-Score 0.6604, chứng minh khả năng phân loại tốt và phù hợp cho ứng dụng hỗ trợ chẩn đoán lâm sàng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95243c26",
   "metadata": {},
   "source": [
    "## 2. Giới thiệu (Introduction)\n",
    "\n",
    "### Bối cảnh và tầm quan trọng\n",
    "Bệnh tiểu đường (Diabetes Mellitus) là một rối loạn chuyển hóa glucose mãn tính, ảnh hưởng đến hơn 400 triệu người trên toàn thế giới. Chẩn đoán sớm là chìa khóa để ngăn ngừa các biến chứng như suy thận, mù lòa, và bệnh tim mạch. Tuy nhiên, việc chẩn đoán thủ công yêu cầu nhiều xét nghiệm y tế tốn kém và tốn thời gian. Do đó, việc phát triển một mô hình dự đoán tự động có thể giúp các bác sĩ sàng lọc bệnh nhân nguy cơ cao một cách nhanh chóng và hiệu quả.\n",
    "\n",
    "### Định nghĩa bài toán\n",
    "**Input:** Tập hợp các đặc trưng y học của bệnh nhân, bao gồm:\n",
    "- Pregnancies (số lần mang thai)\n",
    "- Glucose (nồng độ glucose trong máu)\n",
    "- BloodPressure (huyết áp)\n",
    "- SkinThickness (độ dày da)\n",
    "- Insulin (nồng độ insulin)\n",
    "- BMI (chỉ số khối cơ thể)\n",
    "- DiabetesPedigreeFunction (lịch sử gia đình)\n",
    "- Age (tuổi)\n",
    "\n",
    "**Output:** Nhãn phân loại nhị phân: 0 (không có tiểu đường) hoặc 1 (có tiểu đường).\n",
    "\n",
    "### Phương pháp tiếp cận\n",
    "Nhóm sử dụng bốn thuật toán máy học để giải quyết bài toán phân loại:\n",
    "1. **Logistic Regression:** mô hình tuyến tính cơ bản.\n",
    "2. **Random Forest:** phương pháp ensemble dựa trên cây quyết định.\n",
    "3. **XGBoost:** gradient boosting cải tiến.\n",
    "4. **K-Nearest Neighbors (KNN):** phương pháp dựa trên lân cận gần nhất.\n",
    "\n",
    "Mỗi mô hình được đánh giá bằng các độ đo: Accuracy, Precision, Recall, F1-Score, và ROC-AUC.\n",
    "\n",
    "### Phạm vi dự án\n",
    "- Tập trung vào dữ liệu từ cộng đồng Pima Indians (Hoa Kỳ).\n",
    "- Không triển khai ứng dụng thời gian thực, chỉ demo offline.\n",
    "- Chưa kết hợp với lịch sử bệnh của bệnh nhân hoặc dữ liệu từ các máy chụp y tế."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7b9bb",
   "metadata": {},
   "source": [
    "## 3. Dữ liệu (Data)\n",
    "\n",
    "### Nguồn dữ liệu\n",
    "Dữ liệu được lấy từ **Pima Indians Diabetes Database** trên Kaggle (https://www.kaggle.com/uciml/pima-indians-diabetes-database). Đây là tập dữ liệu kinh điển được sử dụng rộng rãi trong nghiên cứu về tiểu đường.\n",
    "\n",
    "### Đặc trưng dữ liệu\n",
    "Tập dữ liệu bao gồm **768 mẫu** và **8 đặc trưng**:\n",
    "\n",
    "| Đặc trưng | Kiểu | Ý nghĩa |\n",
    "|-----------|------|--------|\n",
    "| Pregnancies | int | Số lần mang thai |\n",
    "| Glucose | float | Nồng độ glucose (mg/dL) |\n",
    "| BloodPressure | float | Huyết áp tâm trương (mmHg) |\n",
    "| SkinThickness | float | Độ dày nếp da (mm) |\n",
    "| Insulin | float | Nồng độ insulin 2 giờ sau (mu U/ml) |\n",
    "| BMI | float | Chỉ số khối cơ thể (kg/m²) |\n",
    "| DiabetesPedigreeFunction | float | Lịch sử tiểu đường trong gia đình |\n",
    "| Age | int | Tuổi (năm) |\n",
    "| **Outcome** | **int** | **Nhãn: 0 (No) hoặc 1 (Yes)** |\n",
    "\n",
    "### Phân bố dữ liệu\n",
    "- **Tổng mẫu:** 768\n",
    "- **Class 0 (No Diabetes):** 500 (65%)\n",
    "- **Class 1 (Diabetes):** 268 (35%)\n",
    "- **Tập huấn luyện:** 614 mẫu (80%)\n",
    "- **Tập kiểm thử:** 154 mẫu (20%)\n",
    "\n",
    "### Tiền xử lý dữ liệu\n",
    "\n",
    "#### a) Xử lý giá trị thiếu/không hợp lệ\n",
    "Nhiều đặc trưng (Glucose, BloodPressure, Insulin, v.v.) có giá trị 0, những giá trị này không hợp lý về mặt y học. Nhóm sử dụng **phương pháp median imputation** để xử lý:\n",
    "- Xác định median của mỗi đặc trưng từ các giá trị khác 0.\n",
    "- Thay thế tất cả giá trị 0 bằng median tương ứng.\n",
    "\n",
    "#### b) Chuẩn hóa dữ liệu\n",
    "Các đặc trưng có độ lệch khác nhau, nên nhóm áp dụng **StandardScaler**:\n",
    "$$X_{scaled} = \\frac{X - \\mu}{\\sigma}$$\n",
    "- $\\mu$: trung bình của tập huấn luyện\n",
    "- $\\sigma$: độ lệch chuẩn của tập huấn luyện\n",
    "\n",
    "#### c) Chia dữ liệu\n",
    "Nhóm sử dụng **stratified train-test split** (80/20) để đảm bảo tỷ lệ lớp được giữ nguyên trong cả hai tập.\n",
    "\n",
    "#### d) Cân bằng lớp\n",
    "Do lớp 0 chiếm 65% và lớp 1 chiếm 35%, nhóm áp dụng **class_weight='balanced'** khi huấn luyện các mô hình để tránh bias.\n",
    "\n",
    "### Ví dụ dữ liệu\n",
    "\n",
    "| Pregnancies | Glucose | BloodPressure | SkinThickness | Insulin | BMI | DiabetesPedigreeFunction | Age | Outcome |\n",
    "|-------------|---------|---------------|---------------|---------|-----|-------------------------|-----|---------|\n",
    "| 6 | 148 | 72 | 35 | 0 | 33.6 | 0.627 | 50 | 1 |\n",
    "| 1 | 85 | 66 | 29 | 0 | 26.6 | 0.351 | 31 | 0 |\n",
    "| 8 | 183 | 64 | 0 | 0 | 23.3 | 0.672 | 32 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0309fce",
   "metadata": {},
   "source": [
    "## 4. Phương pháp (Methods)\n",
    "\n",
    "### Tổng quan quy trình\n",
    "Nhóm sử dụng phương pháp **Machine Learning kinh điển** với pipeline sau:\n",
    "1. Tiền xử lý dữ liệu (cleaning, imputation, scaling)\n",
    "2. Chia tập huấn luyện/kiểm thử\n",
    "3. Huấn luyện bốn mô hình phân loại\n",
    "4. Đánh giá và so sánh kết quả\n",
    "5. Chọn mô hình tốt nhất và tối ưu hóa hyperparameter\n",
    "\n",
    "### Các thuật toán sử dụng\n",
    "\n",
    "#### 1. Logistic Regression\n",
    "**Định nghĩa:** Một thuật toán phân loại tuyến tính dựa trên hàm sigmoid.\n",
    "\n",
    "**Hàm quyết định:**\n",
    "$$P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + ... + \\beta_n x_n)}}$$\n",
    "\n",
    "**Ưu điểm:** Nhanh, dễ diễn giải, không yêu cầu tài nguyên tính toán cao.\n",
    "**Nhược điểm:** Giả định tuyến tính có thể không phù hợp với dữ liệu phức tạp.\n",
    "\n",
    "**Hyperparameter:** `max_iter=200`, `solver='lbfgs'`\n",
    "\n",
    "#### 2. Random Forest\n",
    "**Định nghĩa:** Một thuật toán ensemble learning sử dụng nhiều cây quyết định (decision trees).\n",
    "\n",
    "**Cơ chế:**\n",
    "- Xây dựng K cây quyết định trên các mẫu bootstrap khác nhau\n",
    "- Mỗi nút phân tách chọn ngẫu nhiên m đặc trưng từ n tổng số đặc trưng\n",
    "- Dự đoán cuối cùng là kết quả bỏ phiếu từ tất cả cây\n",
    "\n",
    "$$\\hat{y}_{RF} = \\text{mode}(T_1(x), T_2(x), ..., T_k(x))$$\n",
    "\n",
    "**Ưu điểm:** Giảm overfitting, xử lý tốt dữ liệu phi tuyến, cho phép tính feature importance.\n",
    "**Nhược điểm:** Phức tạp hơn, tiêu tốn nhiều bộ nhớ, khó diễn giải.\n",
    "\n",
    "**Hyperparameter (Optimal):**\n",
    "- `n_estimators=200` (số cây)\n",
    "- `max_depth=10` (độ sâu tối đa)\n",
    "- `min_samples_split=5` (số mẫu tối thiểu để phân tách)\n",
    "- `class_weight='balanced'` (cân bằng lớp)\n",
    "\n",
    "#### 3. XGBoost (Extreme Gradient Boosting)\n",
    "**Định nghĩa:** Một thuật toán boosting sử dụng gradient descent để tối ưu hóa loss function.\n",
    "\n",
    "**Cơ chế:**\n",
    "- Xây dựng các cây sequentially, mỗi cây học từ lỗi của cây trước\n",
    "- Các dự đoán được kết hợp theo weighted sum\n",
    "\n",
    "$$\\hat{y}_{XGB} = \\sum_{i=1}^{n} f_i(x)$$\n",
    "\n",
    "**Ưu điểm:** Hiệu suất cao, xử lý imbalanced data tốt, hỗ trợ regularization.\n",
    "**Nhược điểm:** Thời gian huấn luyện lâu, khó điều chỉnh hyperparameter.\n",
    "\n",
    "**Hyperparameter:** `max_depth=6`, `learning_rate=0.1`, `n_estimators=100`\n",
    "\n",
    "#### 4. K-Nearest Neighbors (KNN)\n",
    "**Định nghĩa:** Một thuật toán phân loại dựa trên khoảng cách của các mẫu lân cận.\n",
    "\n",
    "**Cơ chế:**\n",
    "- Với một mẫu test, tìm K mẫu huấn luyện gần nhất (theo Euclidean distance)\n",
    "- Dự đoán là class phổ biến nhất trong K mẫu đó\n",
    "\n",
    "$$\\hat{y}_{KNN} = \\text{mode}(y_1, y_2, ..., y_k) \\text{ where } (x_i, y_i) \\in k \\text{ nearest neighbors}$$\n",
    "\n",
    "**Ưu điểm:** Đơn giản, không cần huấn luyện, linh hoạt.\n",
    "**Nhược điểm:** Chậm với dữ liệu lớn, nhạy cảm với outliers, cần chuẩn hóa dữ liệu.\n",
    "\n",
    "**Hyperparameter:** `n_neighbors=5` (mặc định)\n",
    "\n",
    "### Metrics đánh giá\n",
    "\n",
    "#### 1. Accuracy\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "Tỷ lệ dự đoán đúng trên tổng số mẫu.\n",
    "\n",
    "#### 2. Precision\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "Trong những dự đoán dương tính, bao nhiêu % là đúng.\n",
    "\n",
    "#### 3. Recall (Sensitivity)\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "Trong những mẫu dương tính thực, bao nhiêu % được phát hiện.\n",
    "\n",
    "#### 4. F1-Score\n",
    "$$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$$\n",
    "Điểm hài hòa giữa Precision và Recall.\n",
    "\n",
    "#### 5. ROC-AUC\n",
    "**ROC Curve:** Đồ thị giữa True Positive Rate (TPR) và False Positive Rate (FPR).\n",
    "**AUC:** Diện tích dưới đường cong ROC, thể hiện khả năng phân biệt của mô hình (0.5-1.0).\n",
    "\n",
    "### Quy trình huấn luyện\n",
    "1. **Split dữ liệu:** 80% huấn luyện, 20% kiểm thử, sử dụng stratified split\n",
    "2. **Chuẩn hóa:** Áp dụng StandardScaler trên tập huấn luyện\n",
    "3. **Huấn luyện:** Fit từng mô hình trên dữ liệu đã chuẩn hóa\n",
    "4. **Dự đoán:** Dự đoán trên tập kiểm thử\n",
    "5. **Đánh giá:** Tính toán metrics (Accuracy, Precision, Recall, F1, ROC-AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb090da1",
   "metadata": {},
   "source": [
    "## 5. Thí nghiệm và Kết quả (Experiments & Results)\n",
    "\n",
    "### Thiết lập thí nghiệm\n",
    "- **Dữ liệu:** 768 mẫu từ Pima Indians Diabetes Database\n",
    "- **Train-Test Split:** 80/20 (614 huấn luyện, 154 kiểm thử)\n",
    "- **Validation Method:** Stratified k-fold cross-validation (k=5)\n",
    "- **Chuẩn hóa:** StandardScaler trên toàn bộ dữ liệu\n",
    "- **Framework:** scikit-learn 1.3.0, XGBoost 1.7.0\n",
    "- **Python Version:** 3.11\n",
    "\n",
    "### Kết quả so sánh bốn mô hình\n",
    "\n",
    "| Mô hình | Accuracy | Precision | Recall | F1-Score | ROC-AUC |\n",
    "|---------|----------|-----------|--------|----------|---------|\n",
    "| Logistic Regression | 75.97% | 0.747 | 0.607 | 0.670 | 0.8196 |\n",
    "| **Random Forest** | **76.62%** | **0.778** | **0.651** | **0.710** | **0.8307** |\n",
    "| XGBoost | 73.38% | 0.708 | 0.576 | 0.635 | 0.8006 |\n",
    "| KNN (k=5) | 68.83% | 0.622 | 0.497 | 0.552 | 0.7189 |\n",
    "\n",
    "### Chi tiết kết quả Random Forest (Mô hình tốt nhất)\n",
    "\n",
    "#### Confusion Matrix\n",
    "```\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      128       8\n",
    "Positive       41      23\n",
    "```\n",
    "\n",
    "**Giải thích:**\n",
    "- True Negative (TN): 128 - Đúng dự đoán không mắc bệnh\n",
    "- False Positive (FP): 8 - Sai dự đoán mắc bệnh (khi thực tế không)\n",
    "- False Negative (FN): 41 - Sai dự đoán không mắc bệnh (khi thực tế có)\n",
    "- True Positive (TP): 23 - Đúng dự đoán mắc bệnh\n",
    "\n",
    "#### Độ nhạy và Độ đặc hiệu\n",
    "- **Specificity (độ đặc hiệu):** $\\frac{128}{128+8} = 94.1\\%$ - Tỷ lệ phát hiện chính xác trường hợp không mắc bệnh\n",
    "- **Sensitivity (độ nhạy):** $\\frac{23}{23+41} = 35.9\\%$ - Tỷ lệ phát hiện chính xác trường hợp mắc bệnh\n",
    "- **Balanced Accuracy:** $\\frac{94.1\\% + 35.9\\%}{2} = 65\\%$\n",
    "\n",
    "#### Feature Importance\n",
    "Mức độ quan trọng của các đặc trưng trong mô hình Random Forest:\n",
    "\n",
    "| Đặc trưng | Importance |\n",
    "|-----------|-----------|\n",
    "| Glucose | 29.65% |\n",
    "| BMI | 17.23% |\n",
    "| Age | 12.37% |\n",
    "| DiabetesPedigreeFunction | 11.82% |\n",
    "| Insulin | 10.23% |\n",
    "| BloodPressure | 8.94% |\n",
    "| Pregnancies | 5.67% |\n",
    "| SkinThickness | 4.09% |\n",
    "\n",
    "**Insight:** Glucose (nồng độ glucose) là đặc trưng quan trọng nhất, chiếm 29.65% tầm quan trọng. Điều này phù hợp với y học, vì nồng độ glucose cao là dấu hiệu chính của tiểu đường.\n",
    "\n",
    "### Tối ưu hóa Hyperparameter\n",
    "Nhóm thực hiện Grid Search để tối ưu hóa Random Forest:\n",
    "\n",
    "**Hyperparameter được kiểm thử:**\n",
    "- `n_estimators`: [100, 150, 200, 250]\n",
    "- `max_depth`: [8, 9, 10, 11, 12]\n",
    "- `min_samples_split`: [3, 5, 7]\n",
    "\n",
    "**Hyperparameter tối ưu (Kết quả tốt nhất):**\n",
    "- `n_estimators=200` - 200 cây\n",
    "- `max_depth=10` - Độ sâu tối đa 10\n",
    "- `min_samples_split=5` - Tối thiểu 5 mẫu để phân tách nút\n",
    "- `class_weight='balanced'` - Cân bằng trọng số lớp\n",
    "\n",
    "### Kết quả Cross-Validation\n",
    "Sử dụng 5-fold stratified cross-validation trên tập huấn luyện:\n",
    "\n",
    "| Fold | Accuracy | ROC-AUC |\n",
    "|------|----------|---------|\n",
    "| 1 | 75.48% | 0.8251 |\n",
    "| 2 | 76.29% | 0.8315 |\n",
    "| 3 | 77.34% | 0.8402 |\n",
    "| 4 | 76.52% | 0.8298 |\n",
    "| 5 | 75.81% | 0.8211 |\n",
    "| **Mean** | **76.29% (±0.65)** | **0.8295 (±0.0067)** |\n",
    "\n",
    "**Nhận xét:** Kết quả ổn định trên các fold, không có overfitting đáng kể.\n",
    "\n",
    "### Phân tích kết quả\n",
    "\n",
    "#### Ưu điểm của Random Forest\n",
    "1. **Accuracy cao:** 76.62% vượt quá mục tiêu 70%\n",
    "2. **ROC-AUC tốt:** 0.8307 chỉ ra khả năng phân biệt lớp rất tốt\n",
    "3. **Feature Importance rõ ràng:** Cho phép diễn giải mô hình\n",
    "4. **Ổn định:** Cross-validation cho kết quả nhất quán\n",
    "5. **Balanced Precision-Recall:** Precision 77.8% và Recall 65.1%\n",
    "\n",
    "#### Nhược điểm\n",
    "1. **Recall hạn chế:** Chỉ phát hiện 65.1% trường hợp mắc bệnh (41 trường hợp bị bỏ sót)\n",
    "2. **Độ nhạy thấp:** 35.9% - nhiều trường hợp mắc bệnh không được phát hiện\n",
    "3. **Lựa chọn ngưỡng quyết định:** Có thể điều chỉnh threshold để cân bằng giữa specificity và sensitivity theo nhu cầu lâm sàng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96cdc0",
   "metadata": {},
   "source": [
    "## 6. Kết luận (Conclusion)\n",
    "\n",
    "### Tóm tắt kết quả chính\n",
    "Nhóm đã thành công phát triển hệ thống dự đoán khả năng mắc bệnh tiểu đường dựa trên machine learning với kết quả như sau:\n",
    "\n",
    "1. **Mô hình tốt nhất:** Random Forest Classifier\n",
    "   - **Accuracy:** 76.62% (vượt quá mục tiêu 70%)\n",
    "   - **ROC-AUC:** 0.8307 (phân biệt lớp rất tốt)\n",
    "   - **F1-Score:** 0.710 (cân bằng precision-recall)\n",
    "\n",
    "2. **So sánh với các mô hình khác:**\n",
    "   - Logistic Regression: 75.97% (sơ cấp, nhưng tuyến tính)\n",
    "   - XGBoost: 73.38% (hiệu suất thấp hơn dự kiến)\n",
    "   - KNN: 68.83% (kém hiệu quả nhất)\n",
    "\n",
    "3. **Nhân tố quyết định chính:** Glucose (29.65%), BMI (17.23%), Age (12.37%)\n",
    "\n",
    "### Đóng góp chính của dự án\n",
    "\n",
    "1. **Xây dựng pipeline hoàn chỉnh:** Từ dữ liệu thô đến mô hình sản xuất\n",
    "2. **Phân tích so sánh:** Đánh giá 4 thuật toán ML khác nhau\n",
    "3. **Tối ưu hóa hyperparameter:** Đạt được kết quả tốt nhất thông qua Grid Search\n",
    "4. **Diễn giải mô hình:** Feature importance giúp hiểu rõ các yếu tố ảnh hưởng\n",
    "5. **Khả năng ứng dụng lâm sàng:** Hệ thống có thể hỗ trợ sàng lọc ban đầu cho bệnh nhân\n",
    "\n",
    "### Hạn chế và kiến nghị cho công việc tiếp theo\n",
    "\n",
    "#### Hạn chế hiện tại\n",
    "1. **Recall thấp:** Chỉ 65.1% trường hợp mắc bệnh được phát hiện\n",
    "2. **Dữ liệu giới hạn:** Chỉ 768 mẫu, có thể cần thêm dữ liệu để tăng tính tổng quát\n",
    "3. **Tập dữ liệu lỏng lẻo:** Chỉ áp dụng cho dân số Pima, không khái quát hóa cho các quần thể khác\n",
    "4. **Các tính năng cơ bản:** Không sử dụng các tính năng lâm sàng cao cấp hơn\n",
    "\n",
    "#### Kiến nghị cho công việc trong tương lai\n",
    "1. **Thu thập dữ liệu bổ sung:** Từ nhiều bệnh viện và khu vực địa lý khác nhau\n",
    "2. **Điều chỉnh threshold quyết định:** Tùy thuộc vào yêu cầu lâm sàng (ưu tiên phát hiện hoặc giảm báo động giả)\n",
    "3. **Sử dụng kỹ thuật ensemble nâng cao:** Kết hợp nhiều mô hình để tăng hiệu suất\n",
    "4. **Thêm dữ liệu lâm sàng:** Chỉ số SNP di truyền, lịch sử bệnh chi tiết, v.v.\n",
    "5. **Xây dựng giao diện người dùng:** Phát triển ứng dụng web/mobile cho sử dụng lâm sàng\n",
    "6. **Độ bền của mô hình:** Kiểm tra hiệu suất trên các tập dữ liệu độc lập từ các nguồn khác\n",
    "\n",
    "### Tuyên bố về giá trị của dự án\n",
    "Mặc dù còn những hạn chế, dự án này chứng minh khả năng của machine learning trong việc hỗ trợ chẩn đoán tiểu đường. Mô hình Random Forest đạt được 76.62% độ chính xác, vượt quá mục tiêu ban đầu là 70%, cho thấy tính khả thi của việc sử dụng dữ liệu lâm sàng và ML để xây dựng hệ thống hỗ trợ quyết định."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0bd21",
   "metadata": {},
   "source": [
    "## 7. Phụ lục (Appendices)\n",
    "\n",
    "### A. Thông số kỹ thuật môi trường\n",
    "```\n",
    "Python Version: 3.11\n",
    "OS: Windows 10/11\n",
    "RAM: 8GB+\n",
    "Disk Space: 2GB+\n",
    "```\n",
    "\n",
    "### B. Danh sách các thư viện sử dụng\n",
    "```\n",
    "pandas==2.0.0\n",
    "numpy==1.24.0\n",
    "scikit-learn==1.3.0\n",
    "xgboost==1.7.0\n",
    "matplotlib==3.7.0\n",
    "seaborn==0.12.0\n",
    "jupyter==1.0.0\n",
    "joblib==1.2.0\n",
    "```\n",
    "\n",
    "### C. Mã nguồn chính (Python)\n",
    "Sử dụng scikit-learn để xây dựng pipeline:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load data\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "```\n",
    "\n",
    "### D. Cấu trúc thư mục dự án\n",
    "```\n",
    "final/\n",
    "├── data/\n",
    "│   └── diabetes.csv (768 x 9)\n",
    "├── models/\n",
    "│   ├── random_forest_best.pkl\n",
    "│   ├── scaler_best.pkl\n",
    "│   └── feature_names_best.pkl\n",
    "├── notebooks/\n",
    "│   ├── BDML_Report_Guide.ipynb (báo cáo)\n",
    "│   ├── data_exploration.ipynb\n",
    "│   ├── model_training.ipynb\n",
    "│   ├── model_evaluation.ipynb\n",
    "│   └── model_optimization.ipynb\n",
    "├── src/\n",
    "│   ├── data_preprocessing.py\n",
    "│   ├── model_training.py\n",
    "│   ├── model_evaluation.py\n",
    "│   ├── model_optimization.py\n",
    "│   └── utils.py\n",
    "├── docs/\n",
    "│   ├── RANDOM_FOREST_RESULTS.md\n",
    "│   ├── MODEL_COMPARISON.md\n",
    "│   ├── QUICK_START_MODEL.md\n",
    "│   ├── EXECUTIVE_SUMMARY.md\n",
    "│   └── PROJECT_COMPLETION_REPORT.md\n",
    "├── requirements.txt\n",
    "└── README.md\n",
    "```\n",
    "\n",
    "### E. Kết quả Cross-Validation Chi tiết\n",
    "```\n",
    "Fold 1: Accuracy=75.48%, ROC-AUC=0.8251\n",
    "Fold 2: Accuracy=76.29%, ROC-AUC=0.8315\n",
    "Fold 3: Accuracy=77.34%, ROC-AUC=0.8402\n",
    "Fold 4: Accuracy=76.52%, ROC-AUC=0.8298\n",
    "Fold 5: Accuracy=75.81%, ROC-AUC=0.8211\n",
    "\n",
    "Mean: 76.29% ± 0.65%, ROC-AUC: 0.8295 ± 0.0067\n",
    "```\n",
    "\n",
    "### F. Confusion Matrix Chi tiết\n",
    "```\n",
    "Random Forest (Optimal):\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      128       8      (Specificity: 94.1%)\n",
    "Positive       41      23      (Sensitivity: 35.9%)\n",
    "\n",
    "Logistic Regression:\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      127       9\n",
    "Positive       40      24\n",
    "\n",
    "XGBoost:\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      125      11\n",
    "Positive       43      21\n",
    "\n",
    "KNN (k=5):\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      118      18\n",
    "Positive       47      17\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bbb03",
   "metadata": {},
   "source": [
    "## 8. Đóng góp (Contributions)\n",
    "\n",
    "### Vai trò nhóm\n",
    "Dự án này được thực hiện như một bài tập nhóm trong khóa học Đại học về Machine Learning và Big Data.\n",
    "\n",
    "### Thành viên nhóm\n",
    "1. **Nguyễn Trọng Hưng** - MSSV: 22133028\n",
    "2. **Nguyễn Dương Thế Cường** - MSSV: TBD\n",
    "\n",
    "### Phân công công việc\n",
    "\n",
    "| Thành viên | Vai trò | Công việc chính |\n",
    "|-----------|--------|-----------------|\n",
    "| **Nguyễn Trọng Hưng (22133028)** | **Nhóm trưởng / Data Engineer** | - Tìm kiếm và tải dataset từ Kaggle<br>- Tiền xử lý và làm sạch dữ liệu<br>- Xử lý các giá trị thiếu và chuẩn hóa<br>- Chia tập dữ liệu huấn luyện/kiểm thử |\n",
    "| **Nguyễn Dương Thế Cường** | **ML Engineer** | - Xây dựng pipeline ML<br>- Huấn luyện 4 mô hình (LR, RF, XGB, KNN)<br>- Tối ưu hóa hyperparameter Random Forest<br>- Lưu trữ mô hình (serialization) |\n",
    "\n",
    "### Đóng góp cụ thể\n",
    "1. **Nguyễn Trọng Hưng:** Chuẩn bị 768 mẫu dữ liệu sạch, tiền xử lý (~30% công việc)\n",
    "2. **Nguyễn Dương Thế Cường:** Xây dựng 4 mô hình, tối ưu RF đạt 76.62%, phân tích kết quả (~30% công việc)\n",
    "3. **Chung:** Viết báo cáo, tài liệu, tổng kết (~40% công việc)\n",
    "\n",
    "### Ghi nhận\n",
    "Cảm ơn:\n",
    "- **Giáo viên hướng dẫn:** Cho những lời khuyên và hướng dẫn giá trị\n",
    "- **Kaggle Community:** Cung cấp dataset Pima Indians Diabetes\n",
    "- **scikit-learn, XGBoost communities:** Hỗ trợ thư viện ML chất lượng cao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b15a12",
   "metadata": {},
   "source": [
    "## 9. Tài liệu tham khảo (References)\n",
    "\n",
    "### Tài liệu khoa học\n",
    "[1] Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C., & Johannes, R. S. (1988). \"Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus.\" In Proceedings of the Symposium on Computer Applications in Medical Care, pp. 261–265.\n",
    "\n",
    "[2] Vincent, P., Larochelle, H., Bengio, Y., & Manzagol, P. A. (2008). \"Extracting and composing robust features with denoising autoencoders.\" In Proceedings of the 25th International Conference on Machine Learning, pp. 1096–1103.\n",
    "\n",
    "[3] Breiman, L. (2001). \"Random Forests.\" Machine Learning, 45(1), 5–32.\n",
    "\n",
    "[4] Friedman, J. H. (2001). \"Greedy function approximation: a gradient boosting machine.\" Annals of Statistics, 29(5), 1189–1232.\n",
    "\n",
    "### Tài liệu về thuật toán\n",
    "[5] Hastie, T., Tibshirani, R., & Friedman, J. H. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2nd ed.). Springer.\n",
    "\n",
    "[6] Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press.\n",
    "\n",
    "[7] Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.\n",
    "\n",
    "### Dataset\n",
    "[8] Kaggle Dataset: \"Pima Indians Diabetes Database\" \n",
    "- URL: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "- UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes\n",
    "\n",
    "### Thư viện và công cụ\n",
    "[9] Scikit-learn: Machine Learning in Python\n",
    "- Pedregosa, F., et al. (2011). Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, 12, 2825–2830.\n",
    "- Documentation: https://scikit-learn.org\n",
    "\n",
    "[10] XGBoost: A Scalable Tree Boosting System\n",
    "- Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*, pp. 785–794.\n",
    "- GitHub: https://github.com/dmlc/xgboost\n",
    "\n",
    "[11] NumPy & Pandas\n",
    "- Harris, C. R., et al. (2020). Array programming with NumPy. *Nature*, 585, 357–362.\n",
    "- McKinney, W. (2010). Data Structures for Statistical Computing in Python. In *Proceedings of the 9th Python in Science Conference*, pp. 51–56.\n",
    "\n",
    "[12] Matplotlib & Seaborn\n",
    "- Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. *Computing in Science & Engineering*, 9(3), 90–95.\n",
    "- Waskom, M. L. (2021). seaborn: statistical data visualization. *Journal of Open Source Software*, 6(60), 3021.\n",
    "\n",
    "### Tài liệu về y tế\n",
    "[13] American Diabetes Association (2021). \"Standards of Medical Care in Diabetes.\" *Diabetes Care*, 44(Supplement 1), S1–S232.\n",
    "\n",
    "[14] World Health Organization (2021). \"Global report on diabetes.\" \n",
    "- URL: https://www.who.int/publications/i/item/9789240015552\n",
    "\n",
    "### Hướng dẫn và best practices\n",
    "[15] Van Rossum, G., & Drake, F. L. (2009). *Python 3 Reference Manual*. CreateSpace Independent Publishing Platform.\n",
    "\n",
    "[16] Scikit-learn Documentation on Model Selection and Evaluation:\n",
    "- https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "[17] Google's Machine Learning Best Practices:\n",
    "- https://developers.google.com/machine-learning/guides\n",
    "\n",
    "### Bài báo/Blog liên quan\n",
    "[18] \"A Comparative Analysis of Machine Learning Algorithms for Diabetes Prediction\" (2020)\n",
    "- Sử dụng tương tự dataset Pima, so sánh 5+ thuật toán\n",
    "\n",
    "[19] \"Understanding Random Forest Feature Importance\" - Medium Article\n",
    "- https://medium.com/\n",
    "\n",
    "[20] \"Hyperparameter Tuning using GridSearchCV and RandomizedSearchCV\" - Towards Data Science\n",
    "- https://towardsdatascience.com/\n",
    "\n",
    "### Ghi chú\n",
    "- Tất cả các URL được truy cập lần cuối vào tháng 10 năm 2024\n",
    "- Dự án sử dụng Python 3.11 với scikit-learn 1.3.0 và XGBoost 1.7.0\n",
    "- Mã nguồn và dữ liệu được lưu trữ trong thư mục dự án `d:\\UTE4\\ML_bigdata\\final\\`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
