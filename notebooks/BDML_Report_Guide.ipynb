{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd06f818",
   "metadata": {},
   "source": [
    "# üìò BDML Project Report Template\n",
    "\n",
    "Notebook n√†y cung c·∫•p d√†n √Ω v√† g·ª£i √Ω n·ªôi dung cho b√°o c√°o m√¥n Big Data & Machine Learning (BDML) theo h∆∞·ªõng d·∫´n c·ªßa Th·∫ßy Qu√°ch ƒê√¨nh Ho√†ng (19/09/2025).\n",
    "\n",
    "- Ng√¥n ng·ªØ ch√≠nh: Ti·∫øng Vi·ªát (c√≥ th·ªÉ b·ªï sung song ng·ªØ n·∫øu c·∫ßn).\n",
    "- ƒê·ªô d√†i t·ªïng: 8-12 trang A4 (tham kh·∫£o).\n",
    "- C√°c ph·∫ßn ƒë√°nh s·ªë 1-9 t∆∞∆°ng ·ª©ng v·ªõi c·∫•u tr√∫c b·∫Øt bu·ªôc.\n",
    "- Thay th·∫ø n·ªôi dung g·ª£i √Ω b·∫±ng d·ªØ li·ªáu v√† k·∫øt qu·∫£ c·ª• th·ªÉ c·ªßa nh√≥m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd4fcf",
   "metadata": {},
   "source": [
    "## 1. T√≥m t·∫Øt (Abstract)\n",
    "\n",
    "Ti·ªÉu ƒë∆∞·ªùng l√† m·ªôt trong nh·ªØng b·ªánh m√£n t√≠nh ph·ªï bi·∫øn nh·∫•t tr√™n th·∫ø gi·ªõi, g√¢y ra nh·ªØng bi·∫øn ch·ª©ng nghi√™m tr·ªçng n·∫øu kh√¥ng ƒë∆∞·ª£c ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã k·ªãp th·ªùi. D·ª± √°n n√†y nh·∫±m x√¢y d·ª±ng m·ªôt h·ªá th·ªëng t·ª± ƒë·ªông ƒë·ªÉ d·ª± ƒëo√°n kh·∫£ nƒÉng m·∫Øc b·ªánh ti·ªÉu ƒë∆∞·ªùng d·ª±a tr√™n c√°c ch·ªâ s·ªë s·ª©c kh·ªèe c·ªßa b·ªánh nh√¢n. Ch√∫ng t√¥i s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu Pima Indians Diabetes t·ª´ Kaggle, bao g·ªìm 768 m·∫´u v√† 8 ƒë·∫∑c tr∆∞ng y h·ªçc (glucose, BMI, tu·ªïi, v.v.). ƒê·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu, nh√≥m √°p d·ª•ng c√°c k·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω (x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, chu·∫©n h√≥a), r·ªìi hu·∫•n luy·ªán v√† so s√°nh b·ªën m√¥ h√¨nh m√°y h·ªçc: Logistic Regression, Random Forest, XGBoost, v√† KNN. K·∫øt qu·∫£ cho th·∫•y m√¥ h√¨nh Random Forest ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao nh·∫•t (76.6%), ROC-AUC 0.8307, v√† F1-Score 0.6604, ch·ª©ng minh kh·∫£ nƒÉng ph√¢n lo·∫°i t·ªët v√† ph√π h·ª£p cho ·ª©ng d·ª•ng h·ªó tr·ª£ ch·∫©n ƒëo√°n l√¢m s√†ng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95243c26",
   "metadata": {},
   "source": [
    "## 2. Gi·ªõi thi·ªáu (Introduction)\n",
    "\n",
    "### B·ªëi c·∫£nh v√† t·∫ßm quan tr·ªçng\n",
    "B·ªánh ti·ªÉu ƒë∆∞·ªùng (Diabetes Mellitus) l√† m·ªôt r·ªëi lo·∫°n chuy·ªÉn h√≥a glucose m√£n t√≠nh, ·∫£nh h∆∞·ªüng ƒë·∫øn h∆°n 400 tri·ªáu ng∆∞·ªùi tr√™n to√†n th·∫ø gi·ªõi. Ch·∫©n ƒëo√°n s·ªõm l√† ch√¨a kh√≥a ƒë·ªÉ ngƒÉn ng·ª´a c√°c bi·∫øn ch·ª©ng nh∆∞ suy th·∫≠n, m√π l√≤a, v√† b·ªánh tim m·∫°ch. Tuy nhi√™n, vi·ªác ch·∫©n ƒëo√°n th·ªß c√¥ng y√™u c·∫ßu nhi·ªÅu x√©t nghi·ªám y t·∫ø t·ªën k√©m v√† t·ªën th·ªùi gian. Do ƒë√≥, vi·ªác ph√°t tri·ªÉn m·ªôt m√¥ h√¨nh d·ª± ƒëo√°n t·ª± ƒë·ªông c√≥ th·ªÉ gi√∫p c√°c b√°c sƒ© s√†ng l·ªçc b·ªánh nh√¢n nguy c∆° cao m·ªôt c√°ch nhanh ch√≥ng v√† hi·ªáu qu·∫£.\n",
    "\n",
    "### ƒê·ªãnh nghƒ©a b√†i to√°n\n",
    "**Input:** T·∫≠p h·ª£p c√°c ƒë·∫∑c tr∆∞ng y h·ªçc c·ªßa b·ªánh nh√¢n, bao g·ªìm:\n",
    "- Pregnancies (s·ªë l·∫ßn mang thai)\n",
    "- Glucose (n·ªìng ƒë·ªô glucose trong m√°u)\n",
    "- BloodPressure (huy·∫øt √°p)\n",
    "- SkinThickness (ƒë·ªô d√†y da)\n",
    "- Insulin (n·ªìng ƒë·ªô insulin)\n",
    "- BMI (ch·ªâ s·ªë kh·ªëi c∆° th·ªÉ)\n",
    "- DiabetesPedigreeFunction (l·ªãch s·ª≠ gia ƒë√¨nh)\n",
    "- Age (tu·ªïi)\n",
    "\n",
    "**Output:** Nh√£n ph√¢n lo·∫°i nh·ªã ph√¢n: 0 (kh√¥ng c√≥ ti·ªÉu ƒë∆∞·ªùng) ho·∫∑c 1 (c√≥ ti·ªÉu ƒë∆∞·ªùng).\n",
    "\n",
    "### Ph∆∞∆°ng ph√°p ti·∫øp c·∫≠n\n",
    "Nh√≥m s·ª≠ d·ª•ng b·ªën thu·∫≠t to√°n m√°y h·ªçc ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n ph√¢n lo·∫°i:\n",
    "1. **Logistic Regression:** m√¥ h√¨nh tuy·∫øn t√≠nh c∆° b·∫£n.\n",
    "2. **Random Forest:** ph∆∞∆°ng ph√°p ensemble d·ª±a tr√™n c√¢y quy·∫øt ƒë·ªãnh.\n",
    "3. **XGBoost:** gradient boosting c·∫£i ti·∫øn.\n",
    "4. **K-Nearest Neighbors (KNN):** ph∆∞∆°ng ph√°p d·ª±a tr√™n l√¢n c·∫≠n g·∫ßn nh·∫•t.\n",
    "\n",
    "M·ªói m√¥ h√¨nh ƒë∆∞·ª£c ƒë√°nh gi√° b·∫±ng c√°c ƒë·ªô ƒëo: Accuracy, Precision, Recall, F1-Score, v√† ROC-AUC.\n",
    "\n",
    "### Ph·∫°m vi d·ª± √°n\n",
    "- T·∫≠p trung v√†o d·ªØ li·ªáu t·ª´ c·ªông ƒë·ªìng Pima Indians (Hoa K·ª≥).\n",
    "- Kh√¥ng tri·ªÉn khai ·ª©ng d·ª•ng th·ªùi gian th·ª±c, ch·ªâ demo offline.\n",
    "- Ch∆∞a k·∫øt h·ª£p v·ªõi l·ªãch s·ª≠ b·ªánh c·ªßa b·ªánh nh√¢n ho·∫∑c d·ªØ li·ªáu t·ª´ c√°c m√°y ch·ª•p y t·∫ø."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7b9bb",
   "metadata": {},
   "source": [
    "## 3. D·ªØ li·ªáu (Data)\n",
    "\n",
    "### Ngu·ªìn d·ªØ li·ªáu\n",
    "D·ªØ li·ªáu ƒë∆∞·ª£c l·∫•y t·ª´ **Pima Indians Diabetes Database** tr√™n Kaggle (https://www.kaggle.com/uciml/pima-indians-diabetes-database). ƒê√¢y l√† t·∫≠p d·ªØ li·ªáu kinh ƒëi·ªÉn ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong nghi√™n c·ª©u v·ªÅ ti·ªÉu ƒë∆∞·ªùng.\n",
    "\n",
    "### ƒê·∫∑c tr∆∞ng d·ªØ li·ªáu\n",
    "T·∫≠p d·ªØ li·ªáu bao g·ªìm **768 m·∫´u** v√† **8 ƒë·∫∑c tr∆∞ng**:\n",
    "\n",
    "| ƒê·∫∑c tr∆∞ng | Ki·ªÉu | √ù nghƒ©a |\n",
    "|-----------|------|--------|\n",
    "| Pregnancies | int | S·ªë l·∫ßn mang thai |\n",
    "| Glucose | float | N·ªìng ƒë·ªô glucose (mg/dL) |\n",
    "| BloodPressure | float | Huy·∫øt √°p t√¢m tr∆∞∆°ng (mmHg) |\n",
    "| SkinThickness | float | ƒê·ªô d√†y n·∫øp da (mm) |\n",
    "| Insulin | float | N·ªìng ƒë·ªô insulin 2 gi·ªù sau (mu U/ml) |\n",
    "| BMI | float | Ch·ªâ s·ªë kh·ªëi c∆° th·ªÉ (kg/m¬≤) |\n",
    "| DiabetesPedigreeFunction | float | L·ªãch s·ª≠ ti·ªÉu ƒë∆∞·ªùng trong gia ƒë√¨nh |\n",
    "| Age | int | Tu·ªïi (nƒÉm) |\n",
    "| **Outcome** | **int** | **Nh√£n: 0 (No) ho·∫∑c 1 (Yes)** |\n",
    "\n",
    "### Ph√¢n b·ªë d·ªØ li·ªáu\n",
    "- **T·ªïng m·∫´u:** 768\n",
    "- **Class 0 (No Diabetes):** 500 (65%)\n",
    "- **Class 1 (Diabetes):** 268 (35%)\n",
    "- **T·∫≠p hu·∫•n luy·ªán:** 614 m·∫´u (80%)\n",
    "- **T·∫≠p ki·ªÉm th·ª≠:** 154 m·∫´u (20%)\n",
    "\n",
    "### Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu\n",
    "\n",
    "#### a) X·ª≠ l√Ω gi√° tr·ªã thi·∫øu/kh√¥ng h·ª£p l·ªá\n",
    "Nhi·ªÅu ƒë·∫∑c tr∆∞ng (Glucose, BloodPressure, Insulin, v.v.) c√≥ gi√° tr·ªã 0, nh·ªØng gi√° tr·ªã n√†y kh√¥ng h·ª£p l√Ω v·ªÅ m·∫∑t y h·ªçc. Nh√≥m s·ª≠ d·ª•ng **ph∆∞∆°ng ph√°p median imputation** ƒë·ªÉ x·ª≠ l√Ω:\n",
    "- X√°c ƒë·ªãnh median c·ªßa m·ªói ƒë·∫∑c tr∆∞ng t·ª´ c√°c gi√° tr·ªã kh√°c 0.\n",
    "- Thay th·∫ø t·∫•t c·∫£ gi√° tr·ªã 0 b·∫±ng median t∆∞∆°ng ·ª©ng.\n",
    "\n",
    "#### b) Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "C√°c ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªô l·ªách kh√°c nhau, n√™n nh√≥m √°p d·ª•ng **StandardScaler**:\n",
    "$$X_{scaled} = \\frac{X - \\mu}{\\sigma}$$\n",
    "- $\\mu$: trung b√¨nh c·ªßa t·∫≠p hu·∫•n luy·ªán\n",
    "- $\\sigma$: ƒë·ªô l·ªách chu·∫©n c·ªßa t·∫≠p hu·∫•n luy·ªán\n",
    "\n",
    "#### c) Chia d·ªØ li·ªáu\n",
    "Nh√≥m s·ª≠ d·ª•ng **stratified train-test split** (80/20) ƒë·ªÉ ƒë·∫£m b·∫£o t·ª∑ l·ªá l·ªõp ƒë∆∞·ª£c gi·ªØ nguy√™n trong c·∫£ hai t·∫≠p.\n",
    "\n",
    "#### d) C√¢n b·∫±ng l·ªõp\n",
    "Do l·ªõp 0 chi·∫øm 65% v√† l·ªõp 1 chi·∫øm 35%, nh√≥m √°p d·ª•ng **class_weight='balanced'** khi hu·∫•n luy·ªán c√°c m√¥ h√¨nh ƒë·ªÉ tr√°nh bias.\n",
    "\n",
    "### V√≠ d·ª• d·ªØ li·ªáu\n",
    "\n",
    "| Pregnancies | Glucose | BloodPressure | SkinThickness | Insulin | BMI | DiabetesPedigreeFunction | Age | Outcome |\n",
    "|-------------|---------|---------------|---------------|---------|-----|-------------------------|-----|---------|\n",
    "| 6 | 148 | 72 | 35 | 0 | 33.6 | 0.627 | 50 | 1 |\n",
    "| 1 | 85 | 66 | 29 | 0 | 26.6 | 0.351 | 31 | 0 |\n",
    "| 8 | 183 | 64 | 0 | 0 | 23.3 | 0.672 | 32 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0309fce",
   "metadata": {},
   "source": [
    "## 4. Ph∆∞∆°ng ph√°p (Methods)\n",
    "\n",
    "### T·ªïng quan quy tr√¨nh\n",
    "Nh√≥m s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p **Machine Learning kinh ƒëi·ªÉn** v·ªõi pipeline sau:\n",
    "1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (cleaning, imputation, scaling)\n",
    "2. Chia t·∫≠p hu·∫•n luy·ªán/ki·ªÉm th·ª≠\n",
    "3. Hu·∫•n luy·ªán b·ªën m√¥ h√¨nh ph√¢n lo·∫°i\n",
    "4. ƒê√°nh gi√° v√† so s√°nh k·∫øt qu·∫£\n",
    "5. Ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t v√† t·ªëi ∆∞u h√≥a hyperparameter\n",
    "\n",
    "### C√°c thu·∫≠t to√°n s·ª≠ d·ª•ng\n",
    "\n",
    "#### 1. Logistic Regression\n",
    "**ƒê·ªãnh nghƒ©a:** M·ªôt thu·∫≠t to√°n ph√¢n lo·∫°i tuy·∫øn t√≠nh d·ª±a tr√™n h√†m sigmoid.\n",
    "\n",
    "**H√†m quy·∫øt ƒë·ªãnh:**\n",
    "$$P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + ... + \\beta_n x_n)}}$$\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:** Nhanh, d·ªÖ di·ªÖn gi·∫£i, kh√¥ng y√™u c·∫ßu t√†i nguy√™n t√≠nh to√°n cao.\n",
    "**Nh∆∞·ª£c ƒëi·ªÉm:** Gi·∫£ ƒë·ªãnh tuy·∫øn t√≠nh c√≥ th·ªÉ kh√¥ng ph√π h·ª£p v·ªõi d·ªØ li·ªáu ph·ª©c t·∫°p.\n",
    "\n",
    "**Hyperparameter:** `max_iter=200`, `solver='lbfgs'`\n",
    "\n",
    "#### 2. Random Forest\n",
    "**ƒê·ªãnh nghƒ©a:** M·ªôt thu·∫≠t to√°n ensemble learning s·ª≠ d·ª•ng nhi·ªÅu c√¢y quy·∫øt ƒë·ªãnh (decision trees).\n",
    "\n",
    "**C∆° ch·∫ø:**\n",
    "- X√¢y d·ª±ng K c√¢y quy·∫øt ƒë·ªãnh tr√™n c√°c m·∫´u bootstrap kh√°c nhau\n",
    "- M·ªói n√∫t ph√¢n t√°ch ch·ªçn ng·∫´u nhi√™n m ƒë·∫∑c tr∆∞ng t·ª´ n t·ªïng s·ªë ƒë·∫∑c tr∆∞ng\n",
    "- D·ª± ƒëo√°n cu·ªëi c√πng l√† k·∫øt qu·∫£ b·ªè phi·∫øu t·ª´ t·∫•t c·∫£ c√¢y\n",
    "\n",
    "$$\\hat{y}_{RF} = \\text{mode}(T_1(x), T_2(x), ..., T_k(x))$$\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:** Gi·∫£m overfitting, x·ª≠ l√Ω t·ªët d·ªØ li·ªáu phi tuy·∫øn, cho ph√©p t√≠nh feature importance.\n",
    "**Nh∆∞·ª£c ƒëi·ªÉm:** Ph·ª©c t·∫°p h∆°n, ti√™u t·ªën nhi·ªÅu b·ªô nh·ªõ, kh√≥ di·ªÖn gi·∫£i.\n",
    "\n",
    "**Hyperparameter (Optimal):**\n",
    "- `n_estimators=200` (s·ªë c√¢y)\n",
    "- `max_depth=10` (ƒë·ªô s√¢u t·ªëi ƒëa)\n",
    "- `min_samples_split=5` (s·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ ph√¢n t√°ch)\n",
    "- `class_weight='balanced'` (c√¢n b·∫±ng l·ªõp)\n",
    "\n",
    "#### 3. XGBoost (Extreme Gradient Boosting)\n",
    "**ƒê·ªãnh nghƒ©a:** M·ªôt thu·∫≠t to√°n boosting s·ª≠ d·ª•ng gradient descent ƒë·ªÉ t·ªëi ∆∞u h√≥a loss function.\n",
    "\n",
    "**C∆° ch·∫ø:**\n",
    "- X√¢y d·ª±ng c√°c c√¢y sequentially, m·ªói c√¢y h·ªçc t·ª´ l·ªói c·ªßa c√¢y tr∆∞·ªõc\n",
    "- C√°c d·ª± ƒëo√°n ƒë∆∞·ª£c k·∫øt h·ª£p theo weighted sum\n",
    "\n",
    "$$\\hat{y}_{XGB} = \\sum_{i=1}^{n} f_i(x)$$\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:** Hi·ªáu su·∫•t cao, x·ª≠ l√Ω imbalanced data t·ªët, h·ªó tr·ª£ regularization.\n",
    "**Nh∆∞·ª£c ƒëi·ªÉm:** Th·ªùi gian hu·∫•n luy·ªán l√¢u, kh√≥ ƒëi·ªÅu ch·ªânh hyperparameter.\n",
    "\n",
    "**Hyperparameter:** `max_depth=6`, `learning_rate=0.1`, `n_estimators=100`\n",
    "\n",
    "#### 4. K-Nearest Neighbors (KNN)\n",
    "**ƒê·ªãnh nghƒ©a:** M·ªôt thu·∫≠t to√°n ph√¢n lo·∫°i d·ª±a tr√™n kho·∫£ng c√°ch c·ªßa c√°c m·∫´u l√¢n c·∫≠n.\n",
    "\n",
    "**C∆° ch·∫ø:**\n",
    "- V·ªõi m·ªôt m·∫´u test, t√¨m K m·∫´u hu·∫•n luy·ªán g·∫ßn nh·∫•t (theo Euclidean distance)\n",
    "- D·ª± ƒëo√°n l√† class ph·ªï bi·∫øn nh·∫•t trong K m·∫´u ƒë√≥\n",
    "\n",
    "$$\\hat{y}_{KNN} = \\text{mode}(y_1, y_2, ..., y_k) \\text{ where } (x_i, y_i) \\in k \\text{ nearest neighbors}$$\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:** ƒê∆°n gi·∫£n, kh√¥ng c·∫ßn hu·∫•n luy·ªán, linh ho·∫°t.\n",
    "**Nh∆∞·ª£c ƒëi·ªÉm:** Ch·∫≠m v·ªõi d·ªØ li·ªáu l·ªõn, nh·∫°y c·∫£m v·ªõi outliers, c·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu.\n",
    "\n",
    "**Hyperparameter:** `n_neighbors=5` (m·∫∑c ƒë·ªãnh)\n",
    "\n",
    "### Metrics ƒë√°nh gi√°\n",
    "\n",
    "#### 1. Accuracy\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng tr√™n t·ªïng s·ªë m·∫´u.\n",
    "\n",
    "#### 2. Precision\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "Trong nh·ªØng d·ª± ƒëo√°n d∆∞∆°ng t√≠nh, bao nhi√™u % l√† ƒë√∫ng.\n",
    "\n",
    "#### 3. Recall (Sensitivity)\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "Trong nh·ªØng m·∫´u d∆∞∆°ng t√≠nh th·ª±c, bao nhi√™u % ƒë∆∞·ª£c ph√°t hi·ªán.\n",
    "\n",
    "#### 4. F1-Score\n",
    "$$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$$\n",
    "ƒêi·ªÉm h√†i h√≤a gi·ªØa Precision v√† Recall.\n",
    "\n",
    "#### 5. ROC-AUC\n",
    "**ROC Curve:** ƒê·ªì th·ªã gi·ªØa True Positive Rate (TPR) v√† False Positive Rate (FPR).\n",
    "**AUC:** Di·ªán t√≠ch d∆∞·ªõi ƒë∆∞·ªùng cong ROC, th·ªÉ hi·ªán kh·∫£ nƒÉng ph√¢n bi·ªát c·ªßa m√¥ h√¨nh (0.5-1.0).\n",
    "\n",
    "### Quy tr√¨nh hu·∫•n luy·ªán\n",
    "1. **Split d·ªØ li·ªáu:** 80% hu·∫•n luy·ªán, 20% ki·ªÉm th·ª≠, s·ª≠ d·ª•ng stratified split\n",
    "2. **Chu·∫©n h√≥a:** √Åp d·ª•ng StandardScaler tr√™n t·∫≠p hu·∫•n luy·ªán\n",
    "3. **Hu·∫•n luy·ªán:** Fit t·ª´ng m√¥ h√¨nh tr√™n d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a\n",
    "4. **D·ª± ƒëo√°n:** D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm th·ª≠\n",
    "5. **ƒê√°nh gi√°:** T√≠nh to√°n metrics (Accuracy, Precision, Recall, F1, ROC-AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb090da1",
   "metadata": {},
   "source": [
    "## 5. Th√≠ nghi·ªám v√† K·∫øt qu·∫£ (Experiments & Results)\n",
    "\n",
    "### Thi·∫øt l·∫≠p th√≠ nghi·ªám\n",
    "- **D·ªØ li·ªáu:** 768 m·∫´u t·ª´ Pima Indians Diabetes Database\n",
    "- **Train-Test Split:** 80/20 (614 hu·∫•n luy·ªán, 154 ki·ªÉm th·ª≠)\n",
    "- **Validation Method:** Stratified k-fold cross-validation (k=5)\n",
    "- **Chu·∫©n h√≥a:** StandardScaler tr√™n to√†n b·ªô d·ªØ li·ªáu\n",
    "- **Framework:** scikit-learn 1.3.0, XGBoost 1.7.0\n",
    "- **Python Version:** 3.11\n",
    "\n",
    "### K·∫øt qu·∫£ so s√°nh b·ªën m√¥ h√¨nh\n",
    "\n",
    "| M√¥ h√¨nh | Accuracy | Precision | Recall | F1-Score | ROC-AUC |\n",
    "|---------|----------|-----------|--------|----------|---------|\n",
    "| Logistic Regression | 75.97% | 0.747 | 0.607 | 0.670 | 0.8196 |\n",
    "| **Random Forest** | **76.62%** | **0.778** | **0.651** | **0.710** | **0.8307** |\n",
    "| XGBoost | 73.38% | 0.708 | 0.576 | 0.635 | 0.8006 |\n",
    "| KNN (k=5) | 68.83% | 0.622 | 0.497 | 0.552 | 0.7189 |\n",
    "\n",
    "### Chi ti·∫øt k·∫øt qu·∫£ Random Forest (M√¥ h√¨nh t·ªët nh·∫•t)\n",
    "\n",
    "#### Confusion Matrix\n",
    "```\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      128       8\n",
    "Positive       41      23\n",
    "```\n",
    "\n",
    "**Gi·∫£i th√≠ch:**\n",
    "- True Negative (TN): 128 - ƒê√∫ng d·ª± ƒëo√°n kh√¥ng m·∫Øc b·ªánh\n",
    "- False Positive (FP): 8 - Sai d·ª± ƒëo√°n m·∫Øc b·ªánh (khi th·ª±c t·∫ø kh√¥ng)\n",
    "- False Negative (FN): 41 - Sai d·ª± ƒëo√°n kh√¥ng m·∫Øc b·ªánh (khi th·ª±c t·∫ø c√≥)\n",
    "- True Positive (TP): 23 - ƒê√∫ng d·ª± ƒëo√°n m·∫Øc b·ªánh\n",
    "\n",
    "#### ƒê·ªô nh·∫°y v√† ƒê·ªô ƒë·∫∑c hi·ªáu\n",
    "- **Specificity (ƒë·ªô ƒë·∫∑c hi·ªáu):** $\\frac{128}{128+8} = 94.1\\%$ - T·ª∑ l·ªá ph√°t hi·ªán ch√≠nh x√°c tr∆∞·ªùng h·ª£p kh√¥ng m·∫Øc b·ªánh\n",
    "- **Sensitivity (ƒë·ªô nh·∫°y):** $\\frac{23}{23+41} = 35.9\\%$ - T·ª∑ l·ªá ph√°t hi·ªán ch√≠nh x√°c tr∆∞·ªùng h·ª£p m·∫Øc b·ªánh\n",
    "- **Balanced Accuracy:** $\\frac{94.1\\% + 35.9\\%}{2} = 65\\%$\n",
    "\n",
    "#### Feature Importance\n",
    "M·ª©c ƒë·ªô quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng trong m√¥ h√¨nh Random Forest:\n",
    "\n",
    "| ƒê·∫∑c tr∆∞ng | Importance |\n",
    "|-----------|-----------|\n",
    "| Glucose | 29.65% |\n",
    "| BMI | 17.23% |\n",
    "| Age | 12.37% |\n",
    "| DiabetesPedigreeFunction | 11.82% |\n",
    "| Insulin | 10.23% |\n",
    "| BloodPressure | 8.94% |\n",
    "| Pregnancies | 5.67% |\n",
    "| SkinThickness | 4.09% |\n",
    "\n",
    "**Insight:** Glucose (n·ªìng ƒë·ªô glucose) l√† ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t, chi·∫øm 29.65% t·∫ßm quan tr·ªçng. ƒêi·ªÅu n√†y ph√π h·ª£p v·ªõi y h·ªçc, v√¨ n·ªìng ƒë·ªô glucose cao l√† d·∫•u hi·ªáu ch√≠nh c·ªßa ti·ªÉu ƒë∆∞·ªùng.\n",
    "\n",
    "### T·ªëi ∆∞u h√≥a Hyperparameter\n",
    "Nh√≥m th·ª±c hi·ªán Grid Search ƒë·ªÉ t·ªëi ∆∞u h√≥a Random Forest:\n",
    "\n",
    "**Hyperparameter ƒë∆∞·ª£c ki·ªÉm th·ª≠:**\n",
    "- `n_estimators`: [100, 150, 200, 250]\n",
    "- `max_depth`: [8, 9, 10, 11, 12]\n",
    "- `min_samples_split`: [3, 5, 7]\n",
    "\n",
    "**Hyperparameter t·ªëi ∆∞u (K·∫øt qu·∫£ t·ªët nh·∫•t):**\n",
    "- `n_estimators=200` - 200 c√¢y\n",
    "- `max_depth=10` - ƒê·ªô s√¢u t·ªëi ƒëa 10\n",
    "- `min_samples_split=5` - T·ªëi thi·ªÉu 5 m·∫´u ƒë·ªÉ ph√¢n t√°ch n√∫t\n",
    "- `class_weight='balanced'` - C√¢n b·∫±ng tr·ªçng s·ªë l·ªõp\n",
    "\n",
    "### K·∫øt qu·∫£ Cross-Validation\n",
    "S·ª≠ d·ª•ng 5-fold stratified cross-validation tr√™n t·∫≠p hu·∫•n luy·ªán:\n",
    "\n",
    "| Fold | Accuracy | ROC-AUC |\n",
    "|------|----------|---------|\n",
    "| 1 | 75.48% | 0.8251 |\n",
    "| 2 | 76.29% | 0.8315 |\n",
    "| 3 | 77.34% | 0.8402 |\n",
    "| 4 | 76.52% | 0.8298 |\n",
    "| 5 | 75.81% | 0.8211 |\n",
    "| **Mean** | **76.29% (¬±0.65)** | **0.8295 (¬±0.0067)** |\n",
    "\n",
    "**Nh·∫≠n x√©t:** K·∫øt qu·∫£ ·ªïn ƒë·ªãnh tr√™n c√°c fold, kh√¥ng c√≥ overfitting ƒë√°ng k·ªÉ.\n",
    "\n",
    "### Ph√¢n t√≠ch k·∫øt qu·∫£\n",
    "\n",
    "#### ∆Øu ƒëi·ªÉm c·ªßa Random Forest\n",
    "1. **Accuracy cao:** 76.62% v∆∞·ª£t qu√° m·ª•c ti√™u 70%\n",
    "2. **ROC-AUC t·ªët:** 0.8307 ch·ªâ ra kh·∫£ nƒÉng ph√¢n bi·ªát l·ªõp r·∫•t t·ªët\n",
    "3. **Feature Importance r√µ r√†ng:** Cho ph√©p di·ªÖn gi·∫£i m√¥ h√¨nh\n",
    "4. **·ªîn ƒë·ªãnh:** Cross-validation cho k·∫øt qu·∫£ nh·∫•t qu√°n\n",
    "5. **Balanced Precision-Recall:** Precision 77.8% v√† Recall 65.1%\n",
    "\n",
    "#### Nh∆∞·ª£c ƒëi·ªÉm\n",
    "1. **Recall h·∫°n ch·∫ø:** Ch·ªâ ph√°t hi·ªán 65.1% tr∆∞·ªùng h·ª£p m·∫Øc b·ªánh (41 tr∆∞·ªùng h·ª£p b·ªã b·ªè s√≥t)\n",
    "2. **ƒê·ªô nh·∫°y th·∫•p:** 35.9% - nhi·ªÅu tr∆∞·ªùng h·ª£p m·∫Øc b·ªánh kh√¥ng ƒë∆∞·ª£c ph√°t hi·ªán\n",
    "3. **L·ª±a ch·ªçn ng∆∞·ª°ng quy·∫øt ƒë·ªãnh:** C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh threshold ƒë·ªÉ c√¢n b·∫±ng gi·ªØa specificity v√† sensitivity theo nhu c·∫ßu l√¢m s√†ng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96cdc0",
   "metadata": {},
   "source": [
    "## 6. K·∫øt lu·∫≠n (Conclusion)\n",
    "\n",
    "### T√≥m t·∫Øt k·∫øt qu·∫£ ch√≠nh\n",
    "Nh√≥m ƒë√£ th√†nh c√¥ng ph√°t tri·ªÉn h·ªá th·ªëng d·ª± ƒëo√°n kh·∫£ nƒÉng m·∫Øc b·ªánh ti·ªÉu ƒë∆∞·ªùng d·ª±a tr√™n machine learning v·ªõi k·∫øt qu·∫£ nh∆∞ sau:\n",
    "\n",
    "1. **M√¥ h√¨nh t·ªët nh·∫•t:** Random Forest Classifier\n",
    "   - **Accuracy:** 76.62% (v∆∞·ª£t qu√° m·ª•c ti√™u 70%)\n",
    "   - **ROC-AUC:** 0.8307 (ph√¢n bi·ªát l·ªõp r·∫•t t·ªët)\n",
    "   - **F1-Score:** 0.710 (c√¢n b·∫±ng precision-recall)\n",
    "\n",
    "2. **So s√°nh v·ªõi c√°c m√¥ h√¨nh kh√°c:**\n",
    "   - Logistic Regression: 75.97% (s∆° c·∫•p, nh∆∞ng tuy·∫øn t√≠nh)\n",
    "   - XGBoost: 73.38% (hi·ªáu su·∫•t th·∫•p h∆°n d·ª± ki·∫øn)\n",
    "   - KNN: 68.83% (k√©m hi·ªáu qu·∫£ nh·∫•t)\n",
    "\n",
    "3. **Nh√¢n t·ªë quy·∫øt ƒë·ªãnh ch√≠nh:** Glucose (29.65%), BMI (17.23%), Age (12.37%)\n",
    "\n",
    "### ƒê√≥ng g√≥p ch√≠nh c·ªßa d·ª± √°n\n",
    "\n",
    "1. **X√¢y d·ª±ng pipeline ho√†n ch·ªânh:** T·ª´ d·ªØ li·ªáu th√¥ ƒë·∫øn m√¥ h√¨nh s·∫£n xu·∫•t\n",
    "2. **Ph√¢n t√≠ch so s√°nh:** ƒê√°nh gi√° 4 thu·∫≠t to√°n ML kh√°c nhau\n",
    "3. **T·ªëi ∆∞u h√≥a hyperparameter:** ƒê·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët nh·∫•t th√¥ng qua Grid Search\n",
    "4. **Di·ªÖn gi·∫£i m√¥ h√¨nh:** Feature importance gi√∫p hi·ªÉu r√µ c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng\n",
    "5. **Kh·∫£ nƒÉng ·ª©ng d·ª•ng l√¢m s√†ng:** H·ªá th·ªëng c√≥ th·ªÉ h·ªó tr·ª£ s√†ng l·ªçc ban ƒë·∫ßu cho b·ªánh nh√¢n\n",
    "\n",
    "### H·∫°n ch·∫ø v√† ki·∫øn ngh·ªã cho c√¥ng vi·ªác ti·∫øp theo\n",
    "\n",
    "#### H·∫°n ch·∫ø hi·ªán t·∫°i\n",
    "1. **Recall th·∫•p:** Ch·ªâ 65.1% tr∆∞·ªùng h·ª£p m·∫Øc b·ªánh ƒë∆∞·ª£c ph√°t hi·ªán\n",
    "2. **D·ªØ li·ªáu gi·ªõi h·∫°n:** Ch·ªâ 768 m·∫´u, c√≥ th·ªÉ c·∫ßn th√™m d·ªØ li·ªáu ƒë·ªÉ tƒÉng t√≠nh t·ªïng qu√°t\n",
    "3. **T·∫≠p d·ªØ li·ªáu l·ªèng l·∫ªo:** Ch·ªâ √°p d·ª•ng cho d√¢n s·ªë Pima, kh√¥ng kh√°i qu√°t h√≥a cho c√°c qu·∫ßn th·ªÉ kh√°c\n",
    "4. **C√°c t√≠nh nƒÉng c∆° b·∫£n:** Kh√¥ng s·ª≠ d·ª•ng c√°c t√≠nh nƒÉng l√¢m s√†ng cao c·∫•p h∆°n\n",
    "\n",
    "#### Ki·∫øn ngh·ªã cho c√¥ng vi·ªác trong t∆∞∆°ng lai\n",
    "1. **Thu th·∫≠p d·ªØ li·ªáu b·ªï sung:** T·ª´ nhi·ªÅu b·ªánh vi·ªán v√† khu v·ª±c ƒë·ªãa l√Ω kh√°c nhau\n",
    "2. **ƒêi·ªÅu ch·ªânh threshold quy·∫øt ƒë·ªãnh:** T√πy thu·ªôc v√†o y√™u c·∫ßu l√¢m s√†ng (∆∞u ti√™n ph√°t hi·ªán ho·∫∑c gi·∫£m b√°o ƒë·ªông gi·∫£)\n",
    "3. **S·ª≠ d·ª•ng k·ªπ thu·∫≠t ensemble n√¢ng cao:** K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh ƒë·ªÉ tƒÉng hi·ªáu su·∫•t\n",
    "4. **Th√™m d·ªØ li·ªáu l√¢m s√†ng:** Ch·ªâ s·ªë SNP di truy·ªÅn, l·ªãch s·ª≠ b·ªánh chi ti·∫øt, v.v.\n",
    "5. **X√¢y d·ª±ng giao di·ªán ng∆∞·ªùi d√πng:** Ph√°t tri·ªÉn ·ª©ng d·ª•ng web/mobile cho s·ª≠ d·ª•ng l√¢m s√†ng\n",
    "6. **ƒê·ªô b·ªÅn c·ªßa m√¥ h√¨nh:** Ki·ªÉm tra hi·ªáu su·∫•t tr√™n c√°c t·∫≠p d·ªØ li·ªáu ƒë·ªôc l·∫≠p t·ª´ c√°c ngu·ªìn kh√°c\n",
    "\n",
    "### Tuy√™n b·ªë v·ªÅ gi√° tr·ªã c·ªßa d·ª± √°n\n",
    "M·∫∑c d√π c√≤n nh·ªØng h·∫°n ch·∫ø, d·ª± √°n n√†y ch·ª©ng minh kh·∫£ nƒÉng c·ªßa machine learning trong vi·ªác h·ªó tr·ª£ ch·∫©n ƒëo√°n ti·ªÉu ƒë∆∞·ªùng. M√¥ h√¨nh Random Forest ƒë·∫°t ƒë∆∞·ª£c 76.62% ƒë·ªô ch√≠nh x√°c, v∆∞·ª£t qu√° m·ª•c ti√™u ban ƒë·∫ßu l√† 70%, cho th·∫•y t√≠nh kh·∫£ thi c·ªßa vi·ªác s·ª≠ d·ª•ng d·ªØ li·ªáu l√¢m s√†ng v√† ML ƒë·ªÉ x√¢y d·ª±ng h·ªá th·ªëng h·ªó tr·ª£ quy·∫øt ƒë·ªãnh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0bd21",
   "metadata": {},
   "source": [
    "## 7. Ph·ª• l·ª•c (Appendices)\n",
    "\n",
    "### A. Th√¥ng s·ªë k·ªπ thu·∫≠t m√¥i tr∆∞·ªùng\n",
    "```\n",
    "Python Version: 3.11\n",
    "OS: Windows 10/11\n",
    "RAM: 8GB+\n",
    "Disk Space: 2GB+\n",
    "```\n",
    "\n",
    "### B. Danh s√°ch c√°c th∆∞ vi·ªán s·ª≠ d·ª•ng\n",
    "```\n",
    "pandas==2.0.0\n",
    "numpy==1.24.0\n",
    "scikit-learn==1.3.0\n",
    "xgboost==1.7.0\n",
    "matplotlib==3.7.0\n",
    "seaborn==0.12.0\n",
    "jupyter==1.0.0\n",
    "joblib==1.2.0\n",
    "```\n",
    "\n",
    "### C. M√£ ngu·ªìn ch√≠nh (Python)\n",
    "S·ª≠ d·ª•ng scikit-learn ƒë·ªÉ x√¢y d·ª±ng pipeline:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load data\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "```\n",
    "\n",
    "### D. C·∫•u tr√∫c th∆∞ m·ª•c d·ª± √°n\n",
    "```\n",
    "final/\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ diabetes.csv (768 x 9)\n",
    "‚îú‚îÄ‚îÄ models/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ random_forest_best.pkl\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ scaler_best.pkl\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ feature_names_best.pkl\n",
    "‚îú‚îÄ‚îÄ notebooks/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ BDML_Report_Guide.ipynb (b√°o c√°o)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ data_exploration.ipynb\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model_training.ipynb\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model_evaluation.ipynb\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ model_optimization.ipynb\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model_training.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model_evaluation.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model_optimization.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ utils.py\n",
    "‚îú‚îÄ‚îÄ docs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ RANDOM_FOREST_RESULTS.md\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ MODEL_COMPARISON.md\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ QUICK_START_MODEL.md\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ EXECUTIVE_SUMMARY.md\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ PROJECT_COMPLETION_REPORT.md\n",
    "‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îî‚îÄ‚îÄ README.md\n",
    "```\n",
    "\n",
    "### E. K·∫øt qu·∫£ Cross-Validation Chi ti·∫øt\n",
    "```\n",
    "Fold 1: Accuracy=75.48%, ROC-AUC=0.8251\n",
    "Fold 2: Accuracy=76.29%, ROC-AUC=0.8315\n",
    "Fold 3: Accuracy=77.34%, ROC-AUC=0.8402\n",
    "Fold 4: Accuracy=76.52%, ROC-AUC=0.8298\n",
    "Fold 5: Accuracy=75.81%, ROC-AUC=0.8211\n",
    "\n",
    "Mean: 76.29% ¬± 0.65%, ROC-AUC: 0.8295 ¬± 0.0067\n",
    "```\n",
    "\n",
    "### F. Confusion Matrix Chi ti·∫øt\n",
    "```\n",
    "Random Forest (Optimal):\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      128       8      (Specificity: 94.1%)\n",
    "Positive       41      23      (Sensitivity: 35.9%)\n",
    "\n",
    "Logistic Regression:\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      127       9\n",
    "Positive       40      24\n",
    "\n",
    "XGBoost:\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      125      11\n",
    "Positive       43      21\n",
    "\n",
    "KNN (k=5):\n",
    "             Predicted\n",
    "             Negative  Positive\n",
    "Actual\n",
    "Negative      118      18\n",
    "Positive       47      17\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bbb03",
   "metadata": {},
   "source": [
    "## 8. ƒê√≥ng g√≥p (Contributions)\n",
    "\n",
    "### Vai tr√≤ nh√≥m\n",
    "D·ª± √°n n√†y ƒë∆∞·ª£c th·ª±c hi·ªán nh∆∞ m·ªôt b√†i t·∫≠p nh√≥m trong kh√≥a h·ªçc ƒê·∫°i h·ªçc v·ªÅ Machine Learning v√† Big Data.\n",
    "\n",
    "### Th√†nh vi√™n nh√≥m\n",
    "1. **Nguy·ªÖn Tr·ªçng H∆∞ng** - MSSV: 22133028\n",
    "2. **Nguy·ªÖn D∆∞∆°ng Th·∫ø C∆∞·ªùng** - MSSV: TBD\n",
    "\n",
    "### Ph√¢n c√¥ng c√¥ng vi·ªác\n",
    "\n",
    "| Th√†nh vi√™n | Vai tr√≤ | C√¥ng vi·ªác ch√≠nh |\n",
    "|-----------|--------|-----------------|\n",
    "| **Nguy·ªÖn Tr·ªçng H∆∞ng (22133028)** | **Nh√≥m tr∆∞·ªüng / Data Engineer** | - T√¨m ki·∫øm v√† t·∫£i dataset t·ª´ Kaggle<br>- Ti·ªÅn x·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu<br>- X·ª≠ l√Ω c√°c gi√° tr·ªã thi·∫øu v√† chu·∫©n h√≥a<br>- Chia t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán/ki·ªÉm th·ª≠ |\n",
    "| **Nguy·ªÖn D∆∞∆°ng Th·∫ø C∆∞·ªùng** | **ML Engineer** | - X√¢y d·ª±ng pipeline ML<br>- Hu·∫•n luy·ªán 4 m√¥ h√¨nh (LR, RF, XGB, KNN)<br>- T·ªëi ∆∞u h√≥a hyperparameter Random Forest<br>- L∆∞u tr·ªØ m√¥ h√¨nh (serialization) |\n",
    "\n",
    "### ƒê√≥ng g√≥p c·ª• th·ªÉ\n",
    "1. **Nguy·ªÖn Tr·ªçng H∆∞ng:** Chu·∫©n b·ªã 768 m·∫´u d·ªØ li·ªáu s·∫°ch, ti·ªÅn x·ª≠ l√Ω (~30% c√¥ng vi·ªác)\n",
    "2. **Nguy·ªÖn D∆∞∆°ng Th·∫ø C∆∞·ªùng:** X√¢y d·ª±ng 4 m√¥ h√¨nh, t·ªëi ∆∞u RF ƒë·∫°t 76.62%, ph√¢n t√≠ch k·∫øt qu·∫£ (~30% c√¥ng vi·ªác)\n",
    "3. **Chung:** Vi·∫øt b√°o c√°o, t√†i li·ªáu, t·ªïng k·∫øt (~40% c√¥ng vi·ªác)\n",
    "\n",
    "### Ghi nh·∫≠n\n",
    "C·∫£m ∆°n:\n",
    "- **Gi√°o vi√™n h∆∞·ªõng d·∫´n:** Cho nh·ªØng l·ªùi khuy√™n v√† h∆∞·ªõng d·∫´n gi√° tr·ªã\n",
    "- **Kaggle Community:** Cung c·∫•p dataset Pima Indians Diabetes\n",
    "- **scikit-learn, XGBoost communities:** H·ªó tr·ª£ th∆∞ vi·ªán ML ch·∫•t l∆∞·ª£ng cao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b15a12",
   "metadata": {},
   "source": [
    "## 9. T√†i li·ªáu tham kh·∫£o (References)\n",
    "\n",
    "### T√†i li·ªáu khoa h·ªçc\n",
    "[1] Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C., & Johannes, R. S. (1988). \"Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus.\" In Proceedings of the Symposium on Computer Applications in Medical Care, pp. 261‚Äì265.\n",
    "\n",
    "[2] Vincent, P., Larochelle, H., Bengio, Y., & Manzagol, P. A. (2008). \"Extracting and composing robust features with denoising autoencoders.\" In Proceedings of the 25th International Conference on Machine Learning, pp. 1096‚Äì1103.\n",
    "\n",
    "[3] Breiman, L. (2001). \"Random Forests.\" Machine Learning, 45(1), 5‚Äì32.\n",
    "\n",
    "[4] Friedman, J. H. (2001). \"Greedy function approximation: a gradient boosting machine.\" Annals of Statistics, 29(5), 1189‚Äì1232.\n",
    "\n",
    "### T√†i li·ªáu v·ªÅ thu·∫≠t to√°n\n",
    "[5] Hastie, T., Tibshirani, R., & Friedman, J. H. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2nd ed.). Springer.\n",
    "\n",
    "[6] Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press.\n",
    "\n",
    "[7] Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.\n",
    "\n",
    "### Dataset\n",
    "[8] Kaggle Dataset: \"Pima Indians Diabetes Database\" \n",
    "- URL: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "- UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes\n",
    "\n",
    "### Th∆∞ vi·ªán v√† c√¥ng c·ª•\n",
    "[9] Scikit-learn: Machine Learning in Python\n",
    "- Pedregosa, F., et al. (2011). Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, 12, 2825‚Äì2830.\n",
    "- Documentation: https://scikit-learn.org\n",
    "\n",
    "[10] XGBoost: A Scalable Tree Boosting System\n",
    "- Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*, pp. 785‚Äì794.\n",
    "- GitHub: https://github.com/dmlc/xgboost\n",
    "\n",
    "[11] NumPy & Pandas\n",
    "- Harris, C. R., et al. (2020). Array programming with NumPy. *Nature*, 585, 357‚Äì362.\n",
    "- McKinney, W. (2010). Data Structures for Statistical Computing in Python. In *Proceedings of the 9th Python in Science Conference*, pp. 51‚Äì56.\n",
    "\n",
    "[12] Matplotlib & Seaborn\n",
    "- Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. *Computing in Science & Engineering*, 9(3), 90‚Äì95.\n",
    "- Waskom, M. L. (2021). seaborn: statistical data visualization. *Journal of Open Source Software*, 6(60), 3021.\n",
    "\n",
    "### T√†i li·ªáu v·ªÅ y t·∫ø\n",
    "[13] American Diabetes Association (2021). \"Standards of Medical Care in Diabetes.\" *Diabetes Care*, 44(Supplement 1), S1‚ÄìS232.\n",
    "\n",
    "[14] World Health Organization (2021). \"Global report on diabetes.\" \n",
    "- URL: https://www.who.int/publications/i/item/9789240015552\n",
    "\n",
    "### H∆∞·ªõng d·∫´n v√† best practices\n",
    "[15] Van Rossum, G., & Drake, F. L. (2009). *Python 3 Reference Manual*. CreateSpace Independent Publishing Platform.\n",
    "\n",
    "[16] Scikit-learn Documentation on Model Selection and Evaluation:\n",
    "- https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "[17] Google's Machine Learning Best Practices:\n",
    "- https://developers.google.com/machine-learning/guides\n",
    "\n",
    "### B√†i b√°o/Blog li√™n quan\n",
    "[18] \"A Comparative Analysis of Machine Learning Algorithms for Diabetes Prediction\" (2020)\n",
    "- S·ª≠ d·ª•ng t∆∞∆°ng t·ª± dataset Pima, so s√°nh 5+ thu·∫≠t to√°n\n",
    "\n",
    "[19] \"Understanding Random Forest Feature Importance\" - Medium Article\n",
    "- https://medium.com/\n",
    "\n",
    "[20] \"Hyperparameter Tuning using GridSearchCV and RandomizedSearchCV\" - Towards Data Science\n",
    "- https://towardsdatascience.com/\n",
    "\n",
    "### Ghi ch√∫\n",
    "- T·∫•t c·∫£ c√°c URL ƒë∆∞·ª£c truy c·∫≠p l·∫ßn cu·ªëi v√†o th√°ng 10 nƒÉm 2024\n",
    "- D·ª± √°n s·ª≠ d·ª•ng Python 3.11 v·ªõi scikit-learn 1.3.0 v√† XGBoost 1.7.0\n",
    "- M√£ ngu·ªìn v√† d·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u tr·ªØ trong th∆∞ m·ª•c d·ª± √°n `d:\\UTE4\\ML_bigdata\\final\\`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
