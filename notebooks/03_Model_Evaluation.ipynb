{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b718f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ÄÃNH GIÃ MÃ” HÃŒNH HOÃ€N THÃ€NH\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“ TÃ³m táº¯t káº¿t quáº£:\")\n",
    "print(f\"- MÃ´ hÃ¬nh tá»‘t nháº¥t: {best_model_name}\")\n",
    "print(f\"- F1-Score: {best_f1:.4f}\")\n",
    "print(f\"- CÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng máº¡nh nháº¥t: Glucose, BMI, Age, Insulin\")\n",
    "print(\"\\nğŸ“ CÃ¡c bÆ°á»›c tiáº¿p theo:\")\n",
    "print(\"1. âœ“ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u\")\n",
    "print(\"2. âœ“ Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh\")\n",
    "print(\"3. âœ“ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh\")\n",
    "print(\"4. â†’ Dá»± Ä‘oÃ¡n nguy cÆ¡ tiá»ƒu Ä‘Æ°á»ng (Demo)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Feature Importance dáº¡ng báº£ng\n",
    "print(\"\\nğŸ“Š Random Forest - Feature Importance Ranking:\")\n",
    "print(\"=\"*60)\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': rf_features,\n",
    "    'Importance': rf_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for idx, row in rf_importance_df.iterrows():\n",
    "    print(f\"{row['Feature']:.<25} {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š XGBoost - Feature Importance Ranking:\")\n",
    "print(\"=\"*60)\n",
    "xgb_importance_df = pd.DataFrame({\n",
    "    'Feature': rf_features,\n",
    "    'Importance': xgb_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for idx, row in xgb_importance_df.iterrows():\n",
    "    print(f\"{row['Feature']:.<25} {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4463bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance cho Random Forest\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Random Forest\n",
    "rf_model = models['Random Forest']\n",
    "rf_importance = rf_model.feature_importances_\n",
    "rf_features = X.columns.tolist()\n",
    "\n",
    "# Sáº¯p xáº¿p\n",
    "rf_indices = np.argsort(rf_importance)[::-1][:8]\n",
    "\n",
    "axes[0].barh(range(len(rf_indices)), rf_importance[rf_indices], color='#3498db', alpha=0.8, edgecolor='black')\n",
    "axes[0].set_yticks(range(len(rf_indices)))\n",
    "axes[0].set_yticklabels([rf_features[i] for i in rf_indices])\n",
    "axes[0].set_xlabel('Feature Importance', fontweight='bold')\n",
    "axes[0].set_title('ğŸ“Š Random Forest - Feature Importance', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = models['XGBoost']\n",
    "xgb_importance = xgb_model.feature_importances_\n",
    "\n",
    "xgb_indices = np.argsort(xgb_importance)[::-1][:8]\n",
    "\n",
    "axes[1].barh(range(len(xgb_indices)), xgb_importance[xgb_indices], color='#e74c3c', alpha=0.8, edgecolor='black')\n",
    "axes[1].set_yticks(range(len(xgb_indices)))\n",
    "axes[1].set_yticklabels([rf_features[i] for i in xgb_indices])\n",
    "axes[1].set_xlabel('Feature Importance', fontweight='bold')\n",
    "axes[1].set_title('ğŸ“Š XGBoost - Feature Importance', fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Feature Importance Ä‘Ã£ Ä‘Æ°á»£c váº½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520372e2",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váº½ ROC Curve cho táº¥t cáº£ mÃ´ hÃ¬nh\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12']\n",
    "\n",
    "for idx, model_name in enumerate(predictions.keys()):\n",
    "    y_pred_proba = predictions[model_name]['y_pred_proba']\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=colors[idx], lw=2, \n",
    "             label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# ÄÆ°á»ng Ä‘á»‘i chá»©ng (diagonal)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.500)')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)', fontweight='bold')\n",
    "plt.ylabel('True Positive Rate (TPR)', fontweight='bold')\n",
    "plt.title('ğŸ“ˆ ROC Curve - Táº¥t Cáº£ MÃ´ HÃ¬nh', fontweight='bold', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ ROC Curve Ä‘Ã£ Ä‘Æ°á»£c váº½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bcbb8",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váº½ Confusion Matrix cho táº¥t cáº£ mÃ´ hÃ¬nh\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('ğŸ” Confusion Matrix cho Táº¥t Cáº£ MÃ´ HÃ¬nh', fontsize=14, fontweight='bold')\n",
    "\n",
    "model_names = list(predictions.keys())\n",
    "\n",
    "for idx, model_name in enumerate(model_names):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    cm = predictions[model_name]['confusion_matrix']\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False,\n",
    "                xticklabels=['KhÃ´ng', 'Máº¯c'], yticklabels=['KhÃ´ng', 'Máº¯c'])\n",
    "    ax.set_title(model_name, fontweight='bold')\n",
    "    ax.set_ylabel('Thá»±c táº¿ (Actual)')\n",
    "    ax.set_xlabel('Dá»± Ä‘oÃ¡n (Predicted)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Confusion Matrix Ä‘Ã£ Ä‘Æ°á»£c váº½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d0b3f",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b283708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh cÃ¡c metrics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('ğŸ“Š So SÃ¡nh Hiá»‡u Suáº¥t CÃ¡c MÃ´ HÃ¬nh', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "metrics_cols = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "for idx, metric in enumerate(metrics_cols):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12']\n",
    "    \n",
    "    bars = ax.bar(range(len(results_df)), results_df[metric], color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    ax.set_ylabel(metric, fontweight='bold')\n",
    "    ax.set_title(f'{metric}', fontweight='bold')\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_xticks(range(len(results_df)))\n",
    "    ax.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # ThÃªm giÃ¡ trá»‹ trÃªn cá»™t\n",
    "    for bar, val in zip(bars, results_df[metric]):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# áº¨n subplot cuá»‘i\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Biá»ƒu Ä‘á»“ so sÃ¡nh Ä‘Ã£ Ä‘Æ°á»£c váº½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f3026",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ So SÃ¡nh CÃ¡c Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ceb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o DataFrame káº¿t quáº£\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nğŸ“‹ Báº£ng So SÃ¡nh Táº¥t Cáº£ MÃ´ HÃ¬nh:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# TÃ¬m mÃ´ hÃ¬nh tá»‘t nháº¥t\n",
    "best_model_idx = results_df['F1-Score'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "best_f1 = results_df.loc[best_model_idx, 'F1-Score']\n",
    "\n",
    "print(f\"\\nğŸ† MÃ´ hÃ¬nh tá»‘t nháº¥t: {best_model_name} (F1-Score: {best_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HÃ m Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred, y_pred_proba, confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# ÄÃ¡nh giÃ¡ táº¥t cáº£ mÃ´ hÃ¬nh\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "print(\"\\nğŸ“Š ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh trÃªn táº­p Test:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    metrics, y_pred, y_pred_proba, cm = evaluate_model(model, X_test_scaled, y_test, model_name)\n",
    "    results.append(metrics)\n",
    "    predictions[model_name] = {\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Accuracy:  {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"  Recall:    {metrics['Recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {metrics['F1-Score']:.4f}\")\n",
    "    print(f\"  ROC-AUC:   {metrics['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7b2fe",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ÄÃ¡nh GiÃ¡ Táº¥t Cáº£ MÃ´ HÃ¬nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1437bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº£i mÃ´ hÃ¬nh tá»« file\n",
    "models = {}\n",
    "model_names = ['Logistic Regression', 'Random Forest', 'XGBoost', 'KNN']\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_path = f'../models/{model_name.replace(\" \", \"_\").lower()}_model.pkl'\n",
    "    model = joblib.load(model_path)\n",
    "    models[model_name] = model\n",
    "    print(f\"âœ“ Táº£i mÃ´ hÃ¬nh: {model_name}\")\n",
    "\n",
    "print(f\"\\nâœ“ Táº¥t cáº£ {len(models)} mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº£i dá»¯ liá»‡u\n",
    "data_path = '../data/diabetes.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (giá»‘ng nhÆ° trong notebook 2)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_clean = df.copy()\n",
    "cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for col in cols_with_zero:\n",
    "    median_val = df_clean[df_clean[col] != 0][col].median()\n",
    "    df_clean.loc[df_clean[col] == 0, col] = median_val\n",
    "\n",
    "X = df_clean.drop('Outcome', axis=1)\n",
    "y = df_clean['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"âœ“ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i vÃ  tiá»n xá»­ lÃ½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e6f80",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Táº£i Dá»¯ Liá»‡u vÃ  MÃ´ HÃ¬nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, auc, confusion_matrix,\n",
    "    classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ CÃ¡c thÆ° viá»‡n Ä‘Ã£ Ä‘Æ°á»£c import thÃ nh cÃ´ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e1a5f",
   "metadata": {},
   "source": [
    "# ğŸ“Š Dá»± Ä‘oÃ¡n Bá»‡nh Tiá»ƒu ÄÆ°á»ng - ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh\n",
    "\n",
    "## Pháº§n 3: ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cÃ¡c mÃ´ hÃ¬nh\n",
    "- Accuracy, Precision, Recall, F1-Score\n",
    "- Confusion Matrix\n",
    "- ROC-AUC Curve\n",
    "- Feature Importance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
